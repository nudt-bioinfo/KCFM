{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cebf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the root directory of the project\n",
    "project_root = Path(\"/home/lxz/scmamba/KCellFM_tutorial/spatial_transcriptomics\").parent.parent\n",
    "# project_root = Path(__file__).parent.parent\n",
    "sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba517206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lxz/tools/anaconda3/envs/scgpt/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from models.model import MambaModel \n",
    "from models.gene_tokenizer import GeneVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb123640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545eee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration parameters\n",
    "class Config:\n",
    "    # Data parameters\n",
    "    train_data_path = \"/home/lxz/scmamba/空转/Hubmap_SB_cross/train.csv\"\n",
    "    model_save_dir = \"/home/lxz/scmamba/model_state/\"\n",
    "    os.makedirs(model_save_dir, exist_ok=True) \n",
    "\n",
    "    # Model parameters\n",
    "    embsize = 512\n",
    "    nhead = 8\n",
    "    d_hid = 512\n",
    "    nlayers = 6\n",
    "    dropout = 0.1\n",
    "    pad_token = \"<pad>\"\n",
    "    max_seq_len = 50\n",
    "    input_emb_style = \"continuous\"\n",
    "    cell_emb_style = \"cls\"\n",
    "    mask_value = -1\n",
    "    pad_value = -2\n",
    "    vocab_path = \"/home/lxz/scmamba/vocab.json\"\n",
    "    pretrained_model_path = \"/home/lxz/scmamba/model_state/cell_cls_3loss_6layer_final.pth\"\n",
    "\n",
    "    # Training parameters\n",
    "    epochs = 10\n",
    "    batch_size = 96  \n",
    "    lr = 2e-4  \n",
    "    weight_decay = 1e-3 \n",
    "    val_split = 0.3  \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Category Mapping\n",
    "    celltype_to_id = {\n",
    "        \"B\": 0,\n",
    "        \"CD4T\": 1,\n",
    "        \"CD7_Immune\": 2,\n",
    "        \"CD8T\": 3,\n",
    "        \"DC\": 4,\n",
    "        \"Endothelial\": 5,\n",
    "        \"Enterocyte_ITLN1p\": 6,\n",
    "        \"Goblet\": 7,\n",
    "        \"ICC\": 8,\n",
    "        \"Lymphatic\": 9,\n",
    "        \"Macrophage\": 10,\n",
    "        \"Nerve\": 11,\n",
    "        \"Neuroendocrine\": 12,\n",
    "        \"Neutrophil\": 13,\n",
    "        \"Plasma\": 14,\n",
    "        \"Stroma\": 15,\n",
    "        \"TA\": 16\n",
    "    }\n",
    "    class_num = len(celltype_to_id)\n",
    "\n",
    "    # Gene Mapping\n",
    "    gene_to_id = {\n",
    "        \"MUC2\": 17183, \"SOX9\": 32052, \"MUC1\": 17175, \"CD31\": 19330, \"Synapto\": 32742,\n",
    "        \"CD49f\": 12272, \"CD15\": 9687, \"CHGA\": 4894, \"CDX2\": 4568, \"ITLN1\": 12308,\n",
    "        \"CD4\": 4380, \"CD127\": 12051, \"Vimentin\": 35192, \"HLADR\": 11044, \"CD8\": 4412,\n",
    "        \"CD11c\": 12283, \"CD44\": 4383, \"CD16\": 9286, \"BCL2\": 3080, \"CD123\": 36627,\n",
    "        \"CD38\": 4376, \"CD90\": 33320, \"aSMA\": 1391, \"CD21\": 5523, \"NKG2D\": 12911,\n",
    "        \"CD66\": 4589, \"CD57\": 2956, \"CD206\": 16892, \"CD68\": 4397, \"CD34\": 4373,\n",
    "        \"aDef5\": 7546, \"CD7\": 4399, \"CD36\": 4374, \"CD138\": 30796, \"Cytokeratin\": 41736,\n",
    "        \"CK7\": 12989, \"CD117\": 12801, \"CD19\": 4335, \"Podoplanin\": 19298, \"CD45\": 20664,\n",
    "        \"CD56\": 17477, \"CD69\": 4398, \"Ki67\": 16711, \"CD49a\": 12264, \"CD163\": 4329,\n",
    "        \"CD161\": 12901\n",
    "    }\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb21aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDataset(Dataset):\n",
    "    def __init__(self, csv_file, gene_to_id, celltype_to_id):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.gene_to_id = gene_to_id\n",
    "        self.celltype_to_id = celltype_to_id\n",
    "        \n",
    "        self.genes = [col for col in self.data.columns if col in gene_to_id]\n",
    "        \n",
    "        valid_cell_types = set(celltype_to_id.keys())\n",
    "        self.data = self.data[self.data['cell_type_A'].isin(valid_cell_types)].reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "\n",
    "        # Obtain gene ID and expression value\n",
    "        vocab_ids = []\n",
    "        expr_values = []\n",
    "        for gene in self.genes:\n",
    "            vocab_ids.append(self.gene_to_id[gene])\n",
    "            expr_values.append(row[gene])\n",
    "\n",
    "        # Add CLS token (assuming 60695 is the CLS token ID)\n",
    "        vocab_ids = [60695] + vocab_ids\n",
    "        expr_values = [0.0] + expr_values\n",
    "\n",
    "        # Sequence filling/truncation\n",
    "        if len(vocab_ids) > config.max_seq_len:\n",
    "            vocab_ids = vocab_ids[:config.max_seq_len]\n",
    "            expr_values = expr_values[:config.max_seq_len]\n",
    "        else:\n",
    "            padding_length = config.max_seq_len - len(vocab_ids)\n",
    "            vocab_ids += [60694] * padding_length  # 60694 is pad token ID\n",
    "            expr_values += [config.pad_value] * padding_length\n",
    "\n",
    "        # Create padding mask (True means mask required)\n",
    "        padding_mask = [False] * config.max_seq_len\n",
    "        for i in range(len(vocab_ids)):\n",
    "            if vocab_ids[i] == 60694:\n",
    "                padding_mask[i] = True\n",
    "\n",
    "        # Obtain cell type ID\n",
    "        cell_type = row['cell_type_A']\n",
    "        cell_type_id = self.celltype_to_id[cell_type]\n",
    "\n",
    "        # spatial coordinates\n",
    "        x, y = row['x'], row['y']\n",
    "\n",
    "        return {\n",
    "            'src': torch.tensor(vocab_ids, dtype=torch.long),\n",
    "            'values': torch.tensor(expr_values, dtype=torch.float),\n",
    "            'padding_mask': torch.tensor(padding_mask, dtype=torch.bool),\n",
    "            'celltype': torch.tensor(cell_type_id, dtype=torch.long),\n",
    "            'coordinates': torch.tensor([x, y], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700f3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate function (correct key name errors, remove redundant parameters)\n",
    "def evaluate(model, loader, device, criterion_cls):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            src = batch['src'].to(device)\n",
    "            values = batch['values'].to(device)\n",
    "            padding_mask = batch['padding_mask'].to(device)\n",
    "            cell_types = batch['celltype'].to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                model_output = model(\n",
    "                    src=src,\n",
    "                    values=values,\n",
    "                    src_key_padding_mask=padding_mask\n",
    "                )\n",
    "                loss = criterion_cls(model_output[\"cls_output\"], cell_types)\n",
    "                total_loss += loss.item() * src.size(0)\n",
    "\n",
    "                preds = torch.argmax(model_output[\"cls_output\"], dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(cell_types.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    return avg_loss, accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c89a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Device setting\n",
    "    device = config.device\n",
    "    torch.cuda.set_device(device)\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Load dataset\n",
    "    full_dataset = SpatialDataset(\n",
    "        csv_file=config.train_data_path,\n",
    "        gene_to_id=config.gene_to_id,\n",
    "        celltype_to_id=config.celltype_to_id\n",
    "    )\n",
    "    print(f\"Total number of training data samples: {len(full_dataset)}\")\n",
    "\n",
    "    # Correctly obtain all labels for stratified sampling\n",
    "    all_labels = [full_dataset[i]['celltype'].item() for i in range(len(full_dataset))]\n",
    "\n",
    "    # Divide the training set and validation set\n",
    "    train_idx, val_idx = train_test_split(\n",
    "        np.arange(len(full_dataset)),\n",
    "        test_size=config.val_split,\n",
    "        stratify=all_labels,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    train_dataset = Subset(full_dataset, train_idx)\n",
    "    val_dataset = Subset(full_dataset, val_idx)\n",
    "    print(f\"Training set size: {len(train_dataset)}, Validation set size: {len(val_dataset)}\")\n",
    "\n",
    "    # Create data loader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    vocab = GeneVocab.from_file(config.vocab_path)\n",
    "    ntokens = len(vocab)\n",
    "\n",
    "    model = MambaModel(\n",
    "        ntokens, config.embsize, config.nhead, config.d_hid, config.nlayers,\n",
    "        dropout=config.dropout, pad_token=config.pad_token,\n",
    "        pad_value=config.pad_value, input_emb_style=config.input_emb_style,\n",
    "        cell_emb_style=config.cell_emb_style, class_num=config.class_num\n",
    "    ).to(device)\n",
    "\n",
    "    # Load pre-training weights\n",
    "    try:\n",
    "        pretrained_dict = torch.load(config.pretrained_model_path, map_location=device)\n",
    "        model_dict = model.state_dict()\n",
    "\n",
    "        # Filter the loadable weights (excluding classification heads)\n",
    "        pretrained_dict_filtered = {\n",
    "            k: v for k, v in pretrained_dict.items()\n",
    "            if k in model_dict and v.shape == model_dict[k].shape and 'cls_decoder' not in k\n",
    "        }\n",
    "\n",
    "        model_dict.update(pretrained_dict_filtered)\n",
    "        model.load_state_dict(model_dict)\n",
    "\n",
    "        print(f\"Successfully loaded {len(pretrained_dict_filtered)} pre training layer weights\")\n",
    "        print(\"Initialize classification header weights...\")\n",
    "        # Reinitialize the classification header\n",
    "        nn.init.kaiming_normal_(model.cls_decoder.out_layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if model.cls_decoder.out_layer.bias is not None:\n",
    "            nn.init.zeros_(model.cls_decoder.out_layer.bias)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load pre training weights: {str(e)}，Random initialization weights will be used\")\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=config.lr,\n",
    "        weight_decay=config.weight_decay\n",
    "    )\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "    best_model_path = os.path.join(config.model_save_dir, \"spatial_classifier_SB_cross_best.pth\")\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{config.epochs}\")\n",
    "        for batch in pbar:\n",
    "            src = batch['src'].to(device)\n",
    "            values = batch['values'].to(device)\n",
    "            padding_mask = batch['padding_mask'].to(device)\n",
    "            cell_types = batch['celltype'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                model_output = model(\n",
    "                    src=src,\n",
    "                    values=values,\n",
    "                    src_key_padding_mask=padding_mask\n",
    "                )\n",
    "                loss = criterion_cls(model_output[\"cls_output\"], cell_types)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            total_train_loss += loss.item() * src.size(0)\n",
    "            pbar.set_postfix(train_loss=loss.item())\n",
    "\n",
    "        # Calculate the average training loss\n",
    "        avg_train_loss = total_train_loss / len(train_dataset)\n",
    "\n",
    "        # Verify\n",
    "        val_loss, val_acc, val_preds, val_labels = evaluate(model, val_loader, device, criterion_cls)\n",
    "\n",
    "        # Print epoch result\n",
    "        print(f\"\\nEpoch {epoch + 1} result:\")\n",
    "        print(f\"Training loss: {avg_train_loss:.4f} | Validation loss: {val_loss:.4f} | Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Save the best model (Validation accuracy: {best_val_acc:.4f}) to {best_model_path}\")\n",
    "\n",
    "    # Print the best results after the training is completed\n",
    "    print(f\"\\nTraining completed! Best Verification Accuracy: {best_val_acc:.4f} (The model is saved in {best_model_path})\")\n",
    "\n",
    "    # Load the best model and print a detailed report of the validation set\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    _, _, val_preds, val_labels = evaluate(model, val_loader, device, criterion_cls)\n",
    "    print(\"\\nDetailed report of the best model on the validation set:\")\n",
    "    print(classification_report(\n",
    "        val_labels,\n",
    "        val_preds,\n",
    "        target_names=config.celltype_to_id.keys(),\n",
    "        digits=4,\n",
    "        zero_division=0\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5692f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Total number of training data samples: 71884\n",
      "Training set size: 50318, Validation set size: 21566\n",
      "Successfully loaded 111 pre training layer weights\n",
      "Initialize classification header weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [01:20<00:00,  6.55it/s, train_loss=0.82]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 32.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 result:\n",
      "Training loss: 0.5215 | Validation loss: 0.3693 | Validation accuracy: 0.8735\n",
      "Save the best model (Validation accuracy: 0.8735) to /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [00:58<00:00,  9.03it/s, train_loss=0.562]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 33.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 result:\n",
      "Training loss: 0.3079 | Validation loss: 0.3390 | Validation accuracy: 0.8751\n",
      "Save the best model (Validation accuracy: 0.8751) to /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [01:06<00:00,  7.95it/s, train_loss=0.238]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:12<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 result:\n",
      "Training loss: 0.2371 | Validation loss: 0.2736 | Validation accuracy: 0.9047\n",
      "Save the best model (Validation accuracy: 0.9047) to /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [01:21<00:00,  6.41it/s, train_loss=0.142]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 33.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 result:\n",
      "Training loss: 0.2161 | Validation loss: 0.2706 | Validation accuracy: 0.9079\n",
      "Save the best model (Validation accuracy: 0.9079) to /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [01:00<00:00,  8.71it/s, train_loss=0.0307]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 result:\n",
      "Training loss: 0.1969 | Validation loss: 0.2675 | Validation accuracy: 0.9094\n",
      "Save the best model (Validation accuracy: 0.9094) to /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  68%|█████████████████████████████████████████████████████████████████████████████████▌                                      | 357/525 [00:46<00:20,  8.23it/s, train_loss=0.184]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 10/10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 525/525 [01:02<00:00,  8.41it/s, train_loss=0.386]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 32.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 result:\n",
      "Training loss: 0.1381 | Validation loss: 0.2987 | Validation accuracy: 0.9105\n",
      "\n",
      "Training completed! Best Verification Accuracy: 0.9139 (The model is saved in /home/lxz/scmamba/model_state/spatial_classifier_SB_cross_best.pth)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 225/225 [00:06<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed report of the best model on the validation set:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "                B     0.8869    0.8896    0.8882       661\n",
      "             CD4T     0.8801    0.8745    0.8773      1578\n",
      "       CD7_Immune     0.7609    0.6731    0.7143        52\n",
      "             CD8T     0.9166    0.9233    0.9199      1238\n",
      "               DC     0.8905    0.7488    0.8135       402\n",
      "      Endothelial     0.9821    0.9831    0.9826      1951\n",
      "Enterocyte_ITLN1p     1.0000    0.4516    0.6222        62\n",
      "           Goblet     0.8827    0.8795    0.8811      2207\n",
      "              ICC     0.8709    0.9385    0.9034       309\n",
      "        Lymphatic     0.8693    0.8159    0.8418       766\n",
      "       Macrophage     0.9459    0.9132    0.9293      2812\n",
      "            Nerve     0.9114    0.9169    0.9142       999\n",
      "   Neuroendocrine     0.8750    0.9686    0.9194       159\n",
      "       Neutrophil     0.9106    0.9333    0.9218       120\n",
      "           Plasma     0.9328    0.9396    0.9362      3428\n",
      "           Stroma     0.8878    0.9543    0.9199      1816\n",
      "               TA     0.9045    0.9172    0.9108      3006\n",
      "\n",
      "         accuracy                         0.9139     21566\n",
      "        macro avg     0.9005    0.8659    0.8762     21566\n",
      "     weighted avg     0.9142    0.9139    0.9134     21566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
